import os
import logging
import json
import re
import time
import subprocess
import asyncio
from pathlib import Path
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from anthropic import Anthropic

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')

if not TELEGRAM_TOKEN or not ANTHROPIC_API_KEY:
    raise ValueError("Missing required environment variables: TELEGRAM_BOT_TOKEN or ANTHROPIC_API_KEY")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Anthropic
client = Anthropic(api_key=ANTHROPIC_API_KEY)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Ä–µ–∂–∏–º–æ–≤ (–æ—Å—Ç–∞—é—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏, —Ç.–∫. —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
spec_mode = {}      # {user_id: bool} - —Ä–µ–∂–∏–º —Å–±–æ—Ä–∞ –¢–ó
models_mode = {}    # {user_id: bool} - —Ä–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
MODELS_CONFIG = {
    'opus': 'claude-opus-4-20250514',
    'sonnet': 'claude-sonnet-4-5-20250929',
    'haiku': 'claude-haiku-4-5-20251001'
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è
COMPRESSION_THRESHOLD = 10  # –°–∂–∏–º–∞—Ç—å –∫–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
MAX_HISTORY_LENGTH = 30     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10 –ú–ë –≤ –±–∞–π—Ç–∞—Ö
CONVERSATIONS_DIR = Path("/root/telegram-bot/conversations")

# –ü—É—Ç—å –∫ MCP —Å–µ—Ä–≤–µ—Ä—É –ø–æ–≥–æ–¥—ã
MCP_WEATHER_SERVER_PATH = "/home/claude/mcp-weather-server/server.js"

# ========================================
# –ú–û–î–£–õ–¨ MCP –ö–õ–ò–ï–ù–¢–ê
# ========================================

class MCPWeatherClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MCP Weather Server"""
    
    def __init__(self, server_path: str):
        self.server_path = server_path
        self.process = None
        self.request_id = 0
    
    async def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç MCP —Å–µ—Ä–≤–µ—Ä –∫–∞–∫ subprocess"""
        try:
            self.process = await asyncio.create_subprocess_exec(
                'node', self.server_path,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            logger.info("‚úì MCP Weather Server started")
        except Exception as e:
            logger.error(f"Failed to start MCP Weather Server: {e}")
            raise
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç MCP —Å–µ—Ä–≤–µ—Ä"""
        if self.process:
            self.process.terminate()
            await self.process.wait()
            logger.info("MCP Weather Server stopped")
    
    async def call_tool(self, tool_name: str, arguments: dict) -> dict:
        """–í—ã–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç MCP —Å–µ—Ä–≤–µ—Ä–∞"""
        if not self.process:
            raise RuntimeError("MCP server not started")
        
        self.request_id += 1
        request = {
            "jsonrpc": "2.0",
            "method": "tools/call",
            "params": {
                "name": tool_name,
                "arguments": arguments
            },
            "id": self.request_id
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        request_json = json.dumps(request) + '\n'
        self.process.stdin.write(request_json.encode())
        await self.process.stdin.drain()
        
        # –ß–∏—Ç–∞–µ–º –æ—Ç–≤–µ—Ç
        response_line = await self.process.stdout.readline()
        response = json.loads(response_line.decode())
        
        if 'error' in response:
            raise RuntimeError(f"MCP error: {response['error']}")
        
        return response.get('result', {})

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä MCP –∫–ª–∏–µ–Ω—Ç–∞
mcp_client = None

# ========================================
# –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° JSON –§–ê–ô–õ–ê–ú–ò
# ========================================

def ensure_conversations_dir():
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    try:
        CONVERSATIONS_DIR.mkdir(parents=True, exist_ok=True)
        logger.info(f"Conversations directory ready: {CONVERSATIONS_DIR}")
    except Exception as e:
        logger.error(f"Failed to create conversations directory: {e}")
        raise


def get_conversation_filepath(user_id: int) -> Path:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏—Å—Ç–æ—Ä–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    return CONVERSATIONS_DIR / f"user_{user_id}.json"


def load_conversation(user_id: int) -> list:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ JSON —Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç.
    """
    filepath = get_conversation_filepath(user_id)
    
    try:
        if not filepath.exists():
            logger.info(f"No conversation file for user {user_id}, returning empty history")
            return []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        file_size = filepath.stat().st_size
        if file_size > MAX_FILE_SIZE:
            logger.warning(f"Conversation file for user {user_id} exceeds max size ({file_size} bytes), truncating")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º –¥–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö MAX_HISTORY_LENGTH —Å–æ–æ–±—â–µ–Ω–∏–π
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                messages = data.get('messages', [])
                if len(messages) > MAX_HISTORY_LENGTH:
                    messages = messages[-MAX_HISTORY_LENGTH:]
                    save_conversation(user_id, messages)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                return messages
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            messages = data.get('messages', [])
            logger.info(f"Loaded {len(messages)} messages for user {user_id}")
            return messages
            
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON in conversation file for user {user_id}: {e}")
        # –°–æ–∑–¥–∞–µ–º backup –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        backup_path = filepath.with_suffix('.json.backup')
        filepath.rename(backup_path)
        logger.info(f"Corrupted file backed up to {backup_path}")
        return []
        
    except Exception as e:
        logger.error(f"Error loading conversation for user {user_id}: {e}", exc_info=True)
        return []


def save_conversation(user_id: int, messages: list) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ JSON —Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞:
    {
        "user_id": 12345,
        "last_updated": "2024-12-14T12:00:00",
        "message_count": 10,
        "messages": [
            {"role": "user", "content": "..."},
            {"role": "assistant", "content": "..."}
        ]
    }
    """
    filepath = get_conversation_filepath(user_id)
    
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–æ–π
        if len(messages) > MAX_HISTORY_LENGTH:
            messages = messages[-MAX_HISTORY_LENGTH:]
            logger.info(f"Truncated conversation for user {user_id} to {MAX_HISTORY_LENGTH} messages")
        
        data = {
            "user_id": user_id,
            "last_updated": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "message_count": len(messages),
            "messages": messages
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        file_size = filepath.stat().st_size
        logger.info(f"Saved {len(messages)} messages for user {user_id} ({file_size} bytes)")
        
        if file_size > MAX_FILE_SIZE:
            logger.warning(f"File size exceeds limit after save, will truncate on next load")
        
        return True
        
    except Exception as e:
        logger.error(f"Error saving conversation for user {user_id}: {e}", exc_info=True)
        return False


def delete_conversation(user_id: int) -> bool:
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    filepath = get_conversation_filepath(user_id)
    
    try:
        if filepath.exists():
            filepath.unlink()
            logger.info(f"Deleted conversation file for user {user_id}")
            return True
        else:
            logger.info(f"No conversation file to delete for user {user_id}")
            return True
            
    except Exception as e:
        logger.error(f"Error deleting conversation for user {user_id}: {e}", exc_info=True)
        return False


def get_conversation_stats(user_id: int) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–∞–π–ª—É –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """
    filepath = get_conversation_filepath(user_id)
    
    if not filepath.exists():
        return {
            "exists": False,
            "message_count": 0,
            "file_size": 0
        }
    
    try:
        file_size = filepath.stat().st_size
        messages = load_conversation(user_id)
        
        return {
            "exists": True,
            "message_count": len(messages),
            "file_size": file_size,
            "file_size_mb": round(file_size / (1024 * 1024), 2)
        }
        
    except Exception as e:
        logger.error(f"Error getting stats for user {user_id}: {e}")
        return {
            "exists": True,
            "message_count": 0,
            "file_size": 0,
            "error": str(e)
        }

# ========================================
# –ö–û–ù–ï–¶ –ú–û–î–£–õ–Ø –†–ê–ë–û–¢–´ –° JSON –§–ê–ô–õ–ê–ú–ò
# ========================================

# –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
NORMAL_SYSTEM_PROMPT = """You are a helpful AI assistant with access to weather information.

TOOLS AVAILABLE:
You have access to a "get_weather" tool that provides current weather data for any city.
When a user asks about weather, you MUST use this tool by including a tool_use block in your response.

RESPONSE FORMAT - CRITICAL:
You must ALWAYS respond with ONLY a valid JSON object containing exactly two fields:
- "user_message": the exact user's message
- "ai_message": your response as a string

CRITICAL RULES:
1. Your entire response must be ONLY the JSON object - nothing before, nothing after
2. Do NOT wrap the JSON in markdown code blocks (no ```json or ```)
3. Do NOT add any explanatory text outside the JSON
4. The JSON must be valid and parseable
5. Both fields must be present in every response

Example of correct response:
{"user_message": "Hello", "ai_message": "Hi! How can I help you today?"}

Example of INCORRECT response:
```json
{"user_message": "Hello", "ai_message": "Hi!"}
```

Remember: ONLY the raw JSON object, nothing else!"""

SPEC_SYSTEM_PROMPT = """You are a business analyst helping to gather requirements for a mobile application. Your task is to collect a comprehensive technical specification through a conversational interview.

RESPONSE FORMAT - CRITICAL:
You must ALWAYS respond with ONLY a valid JSON object containing exactly two fields:
- "user_message": the exact user's message
- "ai_message": your question or final specification as a string

INTERVIEW PROCESS:
1. Ask ONE question at a time, starting from general to specific:
   - Target platform (iOS/Android/Cross-platform)
   - Business logic and app purpose
   - Core features and functionality
   - Data storage requirements
   - User authentication needs
   - External service integrations
   - Design and UI/UX requirements
   - Technical constraints and limitations

2. Internally track what information you've collected

3. After 8-12 meaningful exchanges, when you have enough information, generate the final technical specification in the "ai_message" field formatted like this:

üìã –¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï

üéØ –ü—Ä–æ–µ–∫—Ç: [Name]
üì± –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: [Platform]

üìù –û–ø–∏—Å–∞–Ω–∏–µ:
[Detailed description]

‚öôÔ∏è –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
1. [Feature 1]
2. [Feature 2]
...

üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
[Technical requirements]

üíæ –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:
[Data storage approach]

üîê –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è:
[Auth requirements]

üé® –î–∏–∑–∞–π–Ω:
[Design requirements]

Remember: ONLY the raw JSON object with these two fields, nothing else!"""

MODELS_SYSTEM_PROMPT = """You are a helpful AI assistant. Provide a clear, concise, and accurate response to the user's question.

RESPONSE FORMAT - CRITICAL:
You must ALWAYS respond with ONLY a valid JSON object containing exactly two fields:
- "user_message": the exact user's message
- "ai_message": your response as a string

Keep your response focused and informative, but concise since multiple models will be answering.

Remember: ONLY the raw JSON object, nothing else!"""

COMPRESSION_SYSTEM_PROMPT = """You are a helpful assistant that creates concise summaries of conversation history.

Your task is to create a brief summary of the conversation provided. The summary should:
1. Capture the key topics discussed
2. Preserve important facts, decisions, or conclusions
3. Be concise but informative (2-4 sentences)
4. Be written in the same language as the conversation

Respond with ONLY a valid JSON object:
{"summary": "your summary text here"}

Remember: ONLY the raw JSON object, nothing else!"""


def clean_json_response(text: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞, —É–¥–∞–ª—è—è markdown –∏ –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç"""
    text = text.strip()
    
    # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏ –∫–æ–¥–∞
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤—ã–π JSON –æ–±—ä–µ–∫—Ç
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        return match.group(0)
    
    return text


def serialize_message_content(content):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è Anthropic –≤ JSON-—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç ToolUseBlock, TextBlock –∏ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
    """
    if isinstance(content, str):
        return content
    
    if isinstance(content, list):
        result = []
        for item in content:
            if hasattr(item, 'model_dump'):
                # Anthropic –æ–±—ä–µ–∫—Ç—ã –∏–º–µ—é—Ç –º–µ—Ç–æ–¥ model_dump()
                result.append(item.model_dump())
            elif hasattr(item, 'dict'):
                # –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è pydantic v1
                result.append(item.dict())
            elif isinstance(item, dict):
                result.append(item)
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–∏–ø (str, int –∏ —Ç.–¥.)
                result.append(item)
        return result
    
    # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç Anthropic
    if hasattr(content, 'model_dump'):
        return content.model_dump()
    elif hasattr(content, 'dict'):
        return content.dict()
    
    return content


async def compress_conversation(user_id: int) -> bool:
    """
    –°–∂–∏–º–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, —Å–æ–∑–¥–∞–≤–∞—è —Å–∞–º–º–∞—Ä–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–æ–æ–±—â–µ–Ω–∏–π.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–∞–π–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —Å–∂–∞—Ç–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ.
    """
    try:
        messages = load_conversation(user_id)
        
        if len(messages) < COMPRESSION_THRESHOLD:
            return False
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ COMPRESSION_THRESHOLD —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–∂–∞—Ç–∏—è
        messages_to_compress = messages[-COMPRESSION_THRESHOLD:]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        conversation_text = "\n\n".join([
            f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
            for msg in messages_to_compress
        ])
        
        logger.info(f"Compressing {COMPRESSION_THRESHOLD} messages for user {user_id}")
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–∞–º–º–∞—Ä–∏ —É Claude
        response = client.messages.create(
            model=MODELS_CONFIG['sonnet'],
            max_tokens=500,
            temperature=0.3,
            system=COMPRESSION_SYSTEM_PROMPT,
            messages=[{
                "role": "user",
                "content": f"Create a summary of this conversation:\n\n{conversation_text}"
            }]
        )
        
        raw_response = response.content[0].text
        cleaned_json = clean_json_response(raw_response)
        parsed_json = json.loads(cleaned_json)
        summary = parsed_json.get('summary', '')
        
        if not summary:
            logger.error("Empty summary received, skipping compression")
            return False
        
        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ COMPRESSION_THRESHOLD —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–∞ –æ–¥–Ω–æ —Å–∂–∞—Ç–æ–µ
        messages = messages[:-COMPRESSION_THRESHOLD]
        messages.append({
            "role": "assistant",
            "content": json.dumps({
                "user_message": "[–ò—Å—Ç–æ—Ä–∏—è —Å–∂–∞—Ç–∞]",
                "ai_message": f"üì¶ –°–∂–∞—Ç–∞—è –∏—Å—Ç–æ—Ä–∏—è ({COMPRESSION_THRESHOLD} —Å–æ–æ–±—â–µ–Ω–∏–π): {summary}"
            })
        })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –≤ —Ñ–∞–π–ª
        save_success = save_conversation(user_id, messages)
        
        if save_success:
            logger.info(f"‚úì Successfully compressed and saved conversation for user {user_id}")
            logger.info(f"Summary: {summary[:100]}...")
            return True
        else:
            logger.error(f"Failed to save compressed conversation for user {user_id}")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Error compressing conversation for user {user_id}: {e}", exc_info=True)
        return False


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_id = update.effective_user.id
    
    welcome_message = """üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Claude AI.

üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:

ü§ñ **–û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º** (–∞–∫—Ç–∏–≤–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ—Ç–≤–µ—á—É.
üí° –ò—Å—Ç–æ—Ä–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∂–∏–º–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤.
üå§Ô∏è –ú–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –æ –ø–æ–≥–æ–¥–µ - –ø—Ä–æ—Å—Ç–æ —Å–ø—Ä–æ—Å–∏!

üì± **–†–µ–∂–∏–º /spec**
–ó–∞–ø—É—Å—Ç–∏ –∫–æ–º–∞–Ω–¥–æ–π /spec –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–±–æ—Ä–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –Ω–∞ –º–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.

üî¨ **–†–µ–∂–∏–º /models**
–ó–∞–ø—É—Å—Ç–∏ –∫–æ–º–∞–Ω–¥–æ–π /models –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π Claude (Opus, Sonnet, Haiku) –Ω–∞ –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å.

‚öôÔ∏è **–ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**
/start - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
/spec - –≤–æ–π—Ç–∏ –≤ —Ä–µ–∂–∏–º —Å–±–æ—Ä–∞ –¢–ó
/exit_spec - –≤—ã–π—Ç–∏ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å–±–æ—Ä–∞ –¢–ó
/models - –≤–æ–π—Ç–∏ –≤ —Ä–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
/exit_models - –≤—ã–π—Ç–∏ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
/stats - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å—Ç–æ—Ä–∏–∏
/debug - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π JSON –æ—Ç–≤–µ—Ç"""
    
    await update.message.reply_text(welcome_message, parse_mode='Markdown')
    logger.info(f"User {user_id} started the bot")


async def spec_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /spec - –≤—Ö–æ–¥ –≤ —Ä–µ–∂–∏–º —Å–±–æ—Ä–∞ –¢–ó"""
    user_id = update.effective_user.id
    spec_mode[user_id] = True
    models_mode[user_id] = False  # –í—ã–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º models
    
    # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ —Ä–µ–∂–∏–º spec
    delete_conversation(user_id)
    
    await update.message.reply_text(
        "üìã –†–µ–∂–∏–º —Å–±–æ—Ä–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n\n"
        "–Ø –ø–æ–º–æ–≥—É —Å–æ–±—Ä–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. "
        "–û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –º–æ–∏ –≤–æ–ø—Ä–æ—Å—ã, –∏ —è —Å—Ñ–æ—Ä–º–∏—Ä—É—é –ø–æ–ª–Ω–æ–µ –¢–ó.\n\n"
        "–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /exit_spec"
    )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å
    first_question = "–î–∞–≤–∞–π—Ç–µ –Ω–∞—á–Ω—ë–º! –î–ª—è –∫–∞–∫–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –≤—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: iOS, Android –∏–ª–∏ –∫—Ä–æ—Å—Å-–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ?"
    await update.message.reply_text(first_question)
    
    logger.info(f"User {user_id} entered SPEC mode")


async def exit_spec_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /exit_spec - –≤—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å–±–æ—Ä–∞ –¢–ó"""
    user_id = update.effective_user.id
    spec_mode[user_id] = False
    
    await update.message.reply_text(
        "‚úÖ –í—ã –≤—ã—à–ª–∏ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å–±–æ—Ä–∞ –¢–ó.\n"
        "–¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º. –ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!"
    )
    logger.info(f"User {user_id} exited SPEC mode")


async def models_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /models - –≤—Ö–æ–¥ –≤ —Ä–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    user_id = update.effective_user.id
    models_mode[user_id] = True
    spec_mode[user_id] = False  # –í—ã–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º spec
    
    await update.message.reply_text(
        "üî¨ –†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n\n"
        "–¢–µ–ø–µ—Ä—å –Ω–∞ –∫–∞–∂–¥—ã–π –≤–∞—à –≤–æ–ø—Ä–æ—Å —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å —Ç—Ä–µ–º—è –º–æ–¥–µ–ª—è–º–∏:\n"
        "‚Ä¢ Claude Opus 4\n"
        "‚Ä¢ Claude Sonnet 4.5\n"
        "‚Ä¢ Claude Haiku 4.5\n\n"
        "–í—ã —É–≤–∏–¥–∏—Ç–µ –≤—Å–µ —Ç—Ä–∏ –æ—Ç–≤–µ—Ç–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—Ä–µ–º–µ–Ω–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ç–æ–∫–µ–Ω–æ–≤.\n\n"
        "–î–ª—è –≤—ã—Ö–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /exit_models"
    )
    logger.info(f"User {user_id} entered MODELS mode")


async def exit_models_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /exit_models - –≤—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    user_id = update.effective_user.id
    models_mode[user_id] = False
    
    await update.message.reply_text(
        "‚úÖ –í—ã –≤—ã—à–ª–∏ –∏–∑ —Ä–µ–∂–∏–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.\n"
        "–¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º. –ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!"
    )
    logger.info(f"User {user_id} exited MODELS mode")


async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /clear - –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏"""
    user_id = update.effective_user.id
    success = delete_conversation(user_id)
    
    if success:
        await update.message.reply_text("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞!")
    else:
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
    
    logger.info(f"User {user_id} cleared conversation history")


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /stats - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å—Ç–æ—Ä–∏–∏"""
    user_id = update.effective_user.id
    stats = get_conversation_stats(user_id)
    
    if not stats['exists']:
        await update.message.reply_text("üìä –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏.")
        return
    
    message = f"""üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞—à–µ–π –∏—Å—Ç–æ—Ä–∏–∏:

üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: {stats['message_count']}
üì¶ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {stats['file_size_mb']} –ú–ë
üìÅ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 10 –ú–ë
üìù –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π: {MAX_HISTORY_LENGTH}"""
    
    if stats.get('error'):
        message += f"\n\n‚ö†Ô∏è –û—à–∏–±–∫–∞: {stats['error']}"
    
    await update.message.reply_text(message)
    logger.info(f"User {user_id} requested stats")


async def debug_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /debug - –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π JSON"""
    user_id = update.effective_user.id
    
    messages = load_conversation(user_id)
    
    if not messages:
        await update.message.reply_text("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏.")
        return
    
    last_message = messages[-1]
    formatted_json = json.dumps(last_message, indent=2, ensure_ascii=False)
    
    await update.message.reply_text(f"```json\n{formatted_json}\n```", parse_mode='Markdown')
    logger.info(f"User {user_id} requested debug info")


async def get_claude_response_single(model_name: str, messages: list, system_prompt: str) -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ Claude —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ç–æ–∫–µ–Ω–æ–≤"""
    start_time = time.time()
    
    try:
        response = client.messages.create(
            model=model_name,
            max_tokens=2048,
            temperature=0.3,
            system=system_prompt,
            messages=messages
        )
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        raw_response = response.content[0].text
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–∞—Ö
        input_tokens = response.usage.input_tokens
        output_tokens = response.usage.output_tokens
        total_tokens = input_tokens + output_tokens
        
        return {
            'success': True,
            'raw_response': raw_response,
            'elapsed_time': elapsed_time,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'total_tokens': total_tokens
        }
    except Exception as e:
        end_time = time.time()
        elapsed_time = end_time - start_time
        logger.error(f"Error getting response from {model_name}: {e}")
        return {
            'success': False,
            'error': str(e),
            'elapsed_time': elapsed_time
        }


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    user_message = update.message.text
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∂–∏–º–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if user_id not in spec_mode:
        spec_mode[user_id] = False
    if user_id not in models_mode:
        models_mode[user_id] = False
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    is_spec_mode = spec_mode.get(user_id, False)
    is_models_mode = models_mode.get(user_id, False)
    
    logger.info(f"User {user_id} | Mode: {'MODELS' if is_models_mode else 'SPEC' if is_spec_mode else 'NORMAL'} | Message: {user_message[:50]}...")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    if is_models_mode:
        system_prompt = MODELS_SYSTEM_PROMPT
    elif is_spec_mode:
        system_prompt = SPEC_SYSTEM_PROMPT
    else:
        system_prompt = NORMAL_SYSTEM_PROMPT
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Ñ–∞–π–ª–∞
    messages = load_conversation(user_id)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    messages.append({
        "role": "user",
        "content": user_message
    })
    
    try:
        if is_models_mode:
            # –†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π - –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤—Å–µ —Ç—Ä–∏ –º–æ–¥–µ–ª–∏
            await update.message.reply_text("üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç—ã –æ—Ç —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
            
            results = {}
            for model_key, model_name in MODELS_CONFIG.items():
                result = await get_claude_response_single(
                    model_name=model_name,
                    messages=messages,
                    system_prompt=system_prompt
                )
                results[model_key] = result
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            response_parts = []
            
            for model_key in ['opus', 'sonnet', 'haiku']:
                result = results[model_key]
                model_name_display = {
                    'opus': 'üî∑ Claude Opus 4',
                    'sonnet': 'üî∂ Claude Sonnet 4.5',
                    'haiku': 'üî∏ Claude Haiku 4.5'
                }[model_key]
                
                response_parts.append(f"\n{'='*50}\n{model_name_display}\n{'='*50}\n")
                
                if result['success']:
                    # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                    cleaned_json = clean_json_response(result['raw_response'])
                    try:
                        parsed_json = json.loads(cleaned_json)
                        ai_message = parsed_json.get('ai_message', result['raw_response'])
                    except json.JSONDecodeError:
                        ai_message = result['raw_response']
                    
                    response_parts.append(ai_message)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—é–º–µ
                    minutes = int(result['elapsed_time'] // 60)
                    seconds = int(result['elapsed_time'] % 60)
                    time_str = f"{minutes} –º–∏–Ω {seconds} —Å–µ–∫" if minutes > 0 else f"{seconds} —Å–µ–∫"
                    
                    response_parts.append(
                        f"\n\nüìä –†–µ–∑—é–º–µ:\n"
                        f"‚è± –í—Ä–µ–º—è: {time_str}\n"
                        f"üìù –¢–æ–∫–µ–Ω—ã: {result['total_tokens']} "
                        f"(–≤—Ö–æ–¥: {result['input_tokens']}, –≤—ã—Ö–æ–¥: {result['output_tokens']})"
                    )
                else:
                    response_parts.append(f"‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            
            final_response = ''.join(response_parts)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç (—Ä–∞–∑–±–∏–≤–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)
            if len(final_response) > 4000:
                # Telegram –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ ~4096 —Å–∏–º–≤–æ–ª–æ–≤
                chunks = [final_response[i:i+4000] for i in range(0, len(final_response), 4000)]
                for chunk in chunks:
                    await update.message.reply_text(chunk)
            else:
                await update.message.reply_text(final_response)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
            messages.append({
                "role": "assistant",
                "content": json.dumps({
                    "user_message": user_message,
                    "ai_message": "Multiple model responses provided"
                })
            })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ —Ñ–∞–π–ª
            save_conversation(user_id, messages)
            
        else:
            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –∏–ª–∏ —Ä–µ–∂–∏–º SPEC - –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å
            # –í –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ Claude –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
            tools = None
            if not is_spec_mode:
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ get_weather
                tools = [{
                    "name": "get_weather",
                    "description": "–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –ø–æ–≥–æ–¥—É –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ, –≤–ª–∞–∂–Ω–æ—Å—Ç–∏, –æ—Å–∞–¥–∫–∞—Ö –∏ –≤–µ—Ç—Ä–µ.",
                    "input_schema": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "–ù–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º). –ù–∞–ø—Ä–∏–º–µ—Ä: '–ú–æ—Å–∫–≤–∞', '–¶—é—Ä–∏—Ö', 'London'"
                            }
                        },
                        "required": ["city"]
                    }
                }]
            
            response = client.messages.create(
                model=MODELS_CONFIG['sonnet'],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Sonnet –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                max_tokens=2048,
                temperature=0.3,
                system=system_prompt,
                messages=messages,
                tools=tools
            )
            
            raw_response = response.content[0].text if response.content[0].type == "text" else ""
            logger.info(f"Raw response type: {response.content[0].type}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–∞—Ö
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ tool_use –≤ –æ—Ç–≤–µ—Ç–µ
            tool_use_blocks = [block for block in response.content if block.type == "tool_use"]
            
            if tool_use_blocks and not is_spec_mode:
                # Claude —Ö–æ—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                for tool_use in tool_use_blocks:
                    if tool_use.name == "get_weather":
                        city = tool_use.input.get("city", "")
                        logger.info(f"Claude wants weather for: {city}")
                        
                        try:
                            # –í—ã–∑—ã–≤–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
                            result = await mcp_client.call_tool("get_weather", {"city": city})
                            weather_data = result['content'][0]['text']
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
                            messages.append({
                                "role": "assistant",
                                "content": serialize_message_content(response.content)
                            })
                            messages.append({
                                "role": "user",
                                "content": [{
                                    "type": "tool_result",
                                    "tool_use_id": tool_use.id,
                                    "content": weather_data
                                }]
                            })
                            
                            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–≥–æ–¥–µ
                            final_response = client.messages.create(
                                model=MODELS_CONFIG['sonnet'],
                                max_tokens=2048,
                                temperature=0.3,
                                system=system_prompt,
                                messages=messages,
                                tools=tools
                            )
                            
                            raw_response = final_response.content[0].text
                            input_tokens += final_response.usage.input_tokens
                            output_tokens += final_response.usage.output_tokens
                            
                        except Exception as e:
                            logger.error(f"Error calling MCP weather tool: {e}")
                            await update.message.reply_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ–≥–æ–¥—ã: {str(e)}")
                            return
            
            # –û—á–∏—â–∞–µ–º –∏ –ø–∞—Ä—Å–∏–º JSON
            cleaned_json = clean_json_response(raw_response)
            
            try:
                parsed_json = json.loads(cleaned_json)
                logger.info(f"‚úì Successfully parsed JSON")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
                messages.append({
                    "role": "assistant",
                    "content": cleaned_json
                })
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏ (—Ç–æ–ª—å–∫–æ –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ, –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞)
                if not is_spec_mode:
                    if len(messages) >= COMPRESSION_THRESHOLD:
                        compression_success = await compress_conversation(user_id)
                        if compression_success:
                            await update.message.reply_text("üì¶ –ò—Å—Ç–æ—Ä–∏—è —Å–∂–∞—Ç–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤")
                            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è
                            messages = load_conversation(user_id)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ —Ñ–∞–π–ª
                save_conversation(user_id, messages)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                ai_message = parsed_json.get('ai_message', '')
                
                # –í –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
                if not is_spec_mode:
                    ai_message += f"\n\nüìä –¢–æ–∫–µ–Ω—ã: –≤–æ–ø—Ä–æ—Å {input_tokens} | –æ—Ç–≤–µ—Ç {output_tokens}"
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (Telegram –ª–∏–º–∏—Ç ~4096 —Å–∏–º–≤–æ–ª–æ–≤)
                if len(ai_message) > 4000:
                    chunks = [ai_message[i:i+4000] for i in range(0, len(ai_message), 4000)]
                    for chunk in chunks:
                        await update.message.reply_text(chunk)
                else:
                    await update.message.reply_text(ai_message)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à—ë–Ω –ª–∏ —Å–±–æ—Ä –¢–ó –≤ —Ä–µ–∂–∏–º–µ spec
                if is_spec_mode:
                    if "–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï" in ai_message or "üìã" in ai_message:
                        spec_mode[user_id] = False
                        logger.info(f"User {user_id} - SPEC mode completed, switching to NORMAL")
                        await update.message.reply_text(
                            "\n‚úÖ –°–±–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à—ë–Ω!\n"
                            "–ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –≤ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º."
                        )
                
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Failed to parse JSON: {e}")
                logger.error(f"Cleaned JSON: {cleaned_json[:500]}...")
                
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç —Å —Ä–∞–∑–±–∏–≤–∫–æ–π
                error_message = f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n\n{raw_response}"
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                if len(error_message) > 4000:
                    chunks = [error_message[i:i+4000] for i in range(0, len(error_message), 4000)]
                    for chunk in chunks:
                        await update.message.reply_text(chunk)
                else:
                    await update.message.reply_text(error_message)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                messages.append({
                    "role": "assistant",
                    "content": raw_response
                })
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
                save_conversation(user_id, messages)
    
    except Exception as e:
        logger.error(f"‚ùå Error processing message: {e}", exc_info=True)
        await update.message.reply_text(
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}"
        )


def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    global mcp_client
    
    logger.info("Starting bot...")
    
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
    ensure_conversations_dir()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MCP –∫–ª–∏–µ–Ω—Ç
    mcp_client = MCPWeatherClient(MCP_WEATHER_SERVER_PATH)
    
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("spec", spec_command))
    application.add_handler(CommandHandler("exit_spec", exit_spec_command))
    application.add_handler(CommandHandler("models", models_command))
    application.add_handler(CommandHandler("exit_models", exit_models_command))
    application.add_handler(CommandHandler("clear", clear_command))
    application.add_handler(CommandHandler("stats", stats_command))
    application.add_handler(CommandHandler("debug", debug_command))
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    async def post_init(application):
        await mcp_client.start()
        logger.info("MCP Weather Client initialized")
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä –ø—Ä–∏ –≤—ã–∫–ª—é—á–µ–Ω–∏–∏
    async def post_stop(application):
        await mcp_client.stop()
        logger.info("MCP Weather Client stopped")
    
    application.post_init = post_init
    application.post_shutdown = post_stop
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    logger.info("Bot is running...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
