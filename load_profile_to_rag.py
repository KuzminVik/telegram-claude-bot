#!/usr/bin/env python3
"""Load developer profile into RAG system"""
import asyncio
import sys

sys.path.insert(0, "/root/telegram-bot")

from mcp_clients import init_mcp_clients, mcp_ollama_rag_client, shutdown_mcp_clients
from telegram.ext import Application

async def load_profile():
    print("Initializing MCP clients...")
    app = Application.builder().token("dummy").build()
    await init_mcp_clients(app)
    
    if mcp_ollama_rag_client is None:
        print("‚ùå Ollama RAG client not available")
        return
    
    print("‚úì Ollama RAG client initialized")
    
    profile_text = """# –ü—Ä–æ—Ñ–∏–ª—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞: –í–∏–∫—Ç–æ—Ä –ö—É–∑—å–º–∏–Ω

## –õ–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
–ò–º—è: –í–∏–∫—Ç–æ—Ä –ö—É–∑—å–º–∏–Ω
–†–æ–ª—å: Senior Developer / Systems Architect
–Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π

## –°—Ç–∏–ª—å —Ä–∞–±–æ—Ç—ã
–ü–æ–¥—Ö–æ–¥: –ø—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π
–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è: Build ‚Üí Test ‚Üí Document ‚Üí Improve
–§–æ–∫—É—Å: Production-ready —Ä–µ—à–µ–Ω–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
–û—Å–Ω–æ–≤–Ω—ã–µ —è–∑—ã–∫–∏: Python, JavaScript, Bash
–ò–Ω—Ç–µ—Ä–µ—Å—ã: AI/LLM, DevOps, —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

–ü—Ä–∏–Ω—Ü–∏–ø—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
- –ú–æ–¥—É–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
- Graceful degradation –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- Single source of truth –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

## –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π
- –ü—Ä–æ—Å—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω—ã—Ö
- –ú–µ—Ç—Ä–∏–∫–∏ –∏ data-driven –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ trade-offs –ø–µ—Ä–µ–¥ –≤—ã–±–æ—Ä–æ–º
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç, –∏–∑–º–µ—Ä–µ–Ω–∏–µ, –≤–∞–ª–∏–¥–∞—Ü–∏—è

## –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≤ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
–°—Ç–∏–ª—å: –ö—Ä–∞—Ç–∫–∏–π, code-first –æ—Ç–≤–µ—Ç—ã
Temperature: 0.3
–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á: –ü–æ—à–∞–≥–æ–≤–æ –¥–ª—è –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã—Ö –∑–∞–¥–∞—á

## –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
–ü–∞—Ç—Ç–µ—Ä–Ω: –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ ‚Üí –û—Ç–ª–∞–¥–∏—Ç—å ‚Üí –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ ‚Üí –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å
–ù–∞—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å: –ù–µ —Å–¥–∞–≤–∞—Ç—å—Å—è –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö"""
    
    print(f"\n–ü—Ä–æ—Ñ–∏–ª—å: {len(profile_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    print("\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    result = await mcp_ollama_rag_client.call_tool("chunk_and_embed", {
        "text": profile_text,
        "chunk_size": 800,
        "chunk_overlap": 100
    })
    print(f"‚úì {result}")
    
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ bot_knowledge...")
    result = await mcp_ollama_rag_client.call_tool("vector_store_save", {
        "store_name": "bot_knowledge"
    })
    print(f"‚úì {result}")
    
    await shutdown_mcp_clients(app)
    print("\n‚úÖ –ü—Ä–æ—Ñ–∏–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω!")

if __name__ == "__main__":
    asyncio.run(load_profile())
